{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ff7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54083718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56237989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e294063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8933a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(\"./data/affectnethq/\")\n",
    "test_dir = os.path.dirname(\"./data/test2/\")\n",
    "!find $base_dir -type d -print\n",
    "!find $test_dir -type d -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a986cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AffectNet-HQ dataset\n",
    "train_dir = base_dir\n",
    "\n",
    "train_anger_dir = os.path.join(train_dir, 'anger')\n",
    "train_contempt_dir = os.path.join(train_dir, 'contempt')\n",
    "train_disgust_dir = os.path.join(train_dir, 'disgust')\n",
    "train_fear_dir = os.path.join(train_dir, 'fear')\n",
    "train_happy_dir = os.path.join(train_dir, 'happy')\n",
    "train_neutral_dir = os.path.join(train_dir, 'neutral')\n",
    "train_sad_dir = os.path.join(train_dir, 'sad')\n",
    "train_surprise_dir = os.path.join(train_dir, 'surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c254db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AffectNet-HQ dataset\n",
    "num_anger_tr = len(os.listdir(train_anger_dir))\n",
    "num_contempt_tr = len(os.listdir(train_contempt_dir))\n",
    "num_disgust_tr = len(os.listdir(train_disgust_dir))\n",
    "num_fear_tr = len(os.listdir(train_fear_dir))\n",
    "num_happy_tr = len(os.listdir(train_happy_dir))\n",
    "num_neutral_tr = len(os.listdir(train_neutral_dir))\n",
    "num_sad_tr = len(os.listdir(train_sad_dir))\n",
    "num_surprise_tr = len(os.listdir(train_surprise_dir))\n",
    "\n",
    "total_train = num_anger_tr+num_disgust_tr+num_contempt_tr+num_fear_tr+num_happy_tr+num_neutral_tr+num_sad_tr+num_surprise_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f7c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AffectNet-HQ dataset\n",
    "print('total training anger images:', num_anger_tr)\n",
    "print('total training contempt images:', num_contempt_tr)\n",
    "print('total training disgust images:', num_disgust_tr)\n",
    "print('total training fear images:', num_fear_tr)\n",
    "print('total training happy images:', num_happy_tr)\n",
    "print('total training neutral images:', num_neutral_tr)\n",
    "print('total training sad images:', num_sad_tr)\n",
    "print('total training surprise images:', num_surprise_tr)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de899ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "IMAGE_RES = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AffectNet-HQ dataset\n",
    "image_gen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=25,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest',\n",
    "      validation_split=0.2)\n",
    "\n",
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMAGE_RES,IMAGE_RES),\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     class_mode='categorical',\n",
    "                                                     subset='training')\n",
    "\n",
    "val_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMAGE_RES,IMAGE_RES),\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     class_mode='categorical',\n",
    "                                                     subset='validation')\n",
    "\n",
    "image_gen_test = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = image_gen_test.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                                                     directory=test_dir,\n",
    "                                                     #shuffle=True,\n",
    "                                                     target_size=(IMAGE_RES,IMAGE_RES),\n",
    "                                                     color_mode=\"rgb\",\n",
    "                                                     class_mode='categorical',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe10173",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5cdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.Sequential([\n",
    "#    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMAGE_RES, IMAGE_RES, 3)),\n",
    "#    tf.keras.layers.BatchNormalization(),\n",
    "#    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "#    tf.keras.layers.BatchNormalization(),\n",
    "#    tf.keras.layers.Conv2D(32, (5,5), strides=2, activation='relu'),\n",
    "#    tf.keras.layers.Dropout(0.4),\n",
    "#    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#    tf.keras.layers.BatchNormalization(),\n",
    "#    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "#    tf.keras.layers.BatchNormalization(),\n",
    "#    tf.keras.layers.Conv2D(64, (5,5), strides=2, activation='relu'),\n",
    "#    tf.keras.layers.Dropout(0.4),\n",
    "#    tf.keras.layers.Flatten(),\n",
    "#    tf.keras.layers.Dense(512, activation='relu'),\n",
    "#    tf.keras.layers.BatchNormalization(),\n",
    "#    tf.keras.layers.Dropout(0.4),\n",
    "#    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "#])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19071e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),#from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5863dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5),\n",
    "#    tf.keras.callbacks.ModelCheckpoint(filepath='./models/model.{epoch:02d}-{val_accuracy:.2f}.h5'),\n",
    "#    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "epochs=55\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen, \n",
    "    #callbacks=my_callbacks\n",
    ")\n",
    "\n",
    "print(\"--- %s minutes ---\" % ((time.time() - start_time)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a67f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "export_path_sm = \"./models/{}.h5\".format(int(t))\n",
    "\n",
    "model.save(export_path_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('models/emotions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e0eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y_pred = model.predict(test_data_gen)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "labels = ['anger', 'contempt', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', \"surprise\"]\n",
    "\n",
    "cm = confusion_matrix(test_data_gen.classes, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
    "\n",
    "feature_extractor = hub.KerasLayer(URL,\n",
    "                                   input_shape=(IMAGE_RES, IMAGE_RES,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_extractor,\n",
    "  model.add(Dense(512, activation='relu'))\n",
    "  model.add(Dropout(0.2))\n",
    "  tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),#from_logits=True),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 10\n",
    "history = model.fit(train_data_gen,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=val_data_gen,)\n",
    "\n",
    "print(\"--- %s minutes ---\" % ((time.time() - start_time)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f570f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions  = ['😡 - anger', '🤢 - disgust', '😱 - fear', '😊 - happiness', '😐 - neutral', '😔 - sadness', \"😲 - surprise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_batch = model.predict(test_data_gen)\n",
    "predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
    "predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
    "predicted_class_names = emotions[predicted_ids]\n",
    "predicted_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc1d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "for n in range(30):\n",
    "  plt.subplot(6,5,n+1)\n",
    "  plt.subplots_adjust(hspace = 0.3)\n",
    "  plt.imshow(image_batch[n])\n",
    "  color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n",
    "  plt.title(predicted_class_names[n].title(), color=color)\n",
    "  plt.axis('off')\n",
    "_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec328f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "\n",
    "export_path_sm = \"./models/model{}.h5\".format(int(t))\n",
    "print(export_path_sm)\n",
    "\n",
    "tf.keras.models.save_model(model, export_path_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a8c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
